{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc38c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lichclass/Documents/GitHub/Federated_SeaTurtleReID/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET SeaTurtleID2022: DOWNLOADING STARTED.\n",
      "You are trying to download an already downloaded dataset.\n",
      "        This message may have happened to due interrupted download or extract.\n",
      "        To force the download use the `force=True` keyword such as\n",
      "        get_data(..., force=True) or download(..., force=True).\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>identity</th>\n",
       "      <th>path</th>\n",
       "      <th>bbox</th>\n",
       "      <th>date</th>\n",
       "      <th>orientation</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>original_split</th>\n",
       "      <th>clarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>t001</td>\n",
       "      <td>turtles-data/data/images/t001/CAluWEgwPX.JPG</td>\n",
       "      <td>[644.0, 441.0, 70.0, 78.0]</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>left</td>\n",
       "      <td>{'counts': [858927, 7, 1322, 23, 1306, 34, 129...</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>t001</td>\n",
       "      <td>turtles-data/data/images/t001/EKyrFKHQzh.JPG</td>\n",
       "      <td>[1228.0, 476.0, 110.0, 133.0]</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>right</td>\n",
       "      <td>{'counts': [1637406, 1, 1329, 6, 1326, 8, 1324...</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>t001</td>\n",
       "      <td>turtles-data/data/images/t001/ELAvEqeXxT.JPG</td>\n",
       "      <td>[356.0, 368.0, 119.0, 157.0]</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>left</td>\n",
       "      <td>{'counts': [474978, 29, 1303, 32, 1301, 33, 12...</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>t001</td>\n",
       "      <td>turtles-data/data/images/t001/IxRLFwTGCv.JPG</td>\n",
       "      <td>[1028.0, 500.0, 143.0, 122.0]</td>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>topright</td>\n",
       "      <td>{'counts': [1155982, 9, 1113, 14, 1109, 17, 11...</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>t001</td>\n",
       "      <td>turtles-data/data/images/t001/LKCJAhfLBJ.JPG</td>\n",
       "      <td>[1128.0, 582.0, 50.0, 68.0]</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>right</td>\n",
       "      <td>{'counts': [1504206, 8, 1325, 20, 1313, 26, 13...</td>\n",
       "      <td>test</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "   image_id identity                                          path  \\\n",
       "\u001b[1;36m0\u001b[0m         \u001b[1;36m1\u001b[0m     t001  turtles-data/data/images/t001/CAluWEgwPX.JPG   \n",
       "\u001b[1;36m1\u001b[0m         \u001b[1;36m2\u001b[0m     t001  turtles-data/data/images/t001/EKyrFKHQzh.JPG   \n",
       "\u001b[1;36m2\u001b[0m         \u001b[1;36m3\u001b[0m     t001  turtles-data/data/images/t001/ELAvEqeXxT.JPG   \n",
       "\u001b[1;36m3\u001b[0m         \u001b[1;36m4\u001b[0m     t001  turtles-data/data/images/t001/IxRLFwTGCv.JPG   \n",
       "\u001b[1;36m4\u001b[0m         \u001b[1;36m5\u001b[0m     t001  turtles-data/data/images/t001/LKCJAhfLBJ.JPG   \n",
       "\n",
       "                            bbox        date orientation  \\\n",
       "\u001b[1;36m0\u001b[0m     \u001b[1m[\u001b[0m\u001b[1;36m644.0\u001b[0m, \u001b[1;36m441.0\u001b[0m, \u001b[1;36m70.0\u001b[0m, \u001b[1;36m78.0\u001b[0m\u001b[1m]\u001b[0m  \u001b[1;36m2014\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m14\u001b[0m        left   \n",
       "\u001b[1;36m1\u001b[0m  \u001b[1m[\u001b[0m\u001b[1;36m1228.0\u001b[0m, \u001b[1;36m476.0\u001b[0m, \u001b[1;36m110.0\u001b[0m, \u001b[1;36m133.0\u001b[0m\u001b[1m]\u001b[0m  \u001b[1;36m2014\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m14\u001b[0m       right   \n",
       "\u001b[1;36m2\u001b[0m   \u001b[1m[\u001b[0m\u001b[1;36m356.0\u001b[0m, \u001b[1;36m368.0\u001b[0m, \u001b[1;36m119.0\u001b[0m, \u001b[1;36m157.0\u001b[0m\u001b[1m]\u001b[0m  \u001b[1;36m2014\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m14\u001b[0m        left   \n",
       "\u001b[1;36m3\u001b[0m  \u001b[1m[\u001b[0m\u001b[1;36m1028.0\u001b[0m, \u001b[1;36m500.0\u001b[0m, \u001b[1;36m143.0\u001b[0m, \u001b[1;36m122.0\u001b[0m\u001b[1m]\u001b[0m  \u001b[1;36m2010\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m02\u001b[0m    topright   \n",
       "\u001b[1;36m4\u001b[0m    \u001b[1m[\u001b[0m\u001b[1;36m1128.0\u001b[0m, \u001b[1;36m582.0\u001b[0m, \u001b[1;36m50.0\u001b[0m, \u001b[1;36m68.0\u001b[0m\u001b[1m]\u001b[0m  \u001b[1;36m2014\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m14\u001b[0m       right   \n",
       "\n",
       "                                        segmentation original_split  clarity  \n",
       "\u001b[1;36m0\u001b[0m  \u001b[1m{\u001b[0m\u001b[32m'counts'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m858927\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m1322\u001b[0m, \u001b[1;36m23\u001b[0m, \u001b[1;36m1306\u001b[0m, \u001b[1;36m34\u001b[0m, \u001b[1;36m129\u001b[0m\u001b[33m...\u001b[0m           test        \u001b[1;36m3\u001b[0m  \n",
       "\u001b[1;36m1\u001b[0m  \u001b[1m{\u001b[0m\u001b[32m'counts'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m1637406\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1329\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m1326\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m1324\u001b[0m\u001b[33m...\u001b[0m           test        \u001b[1;36m2\u001b[0m  \n",
       "\u001b[1;36m2\u001b[0m  \u001b[1m{\u001b[0m\u001b[32m'counts'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m474978\u001b[0m, \u001b[1;36m29\u001b[0m, \u001b[1;36m1303\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m1301\u001b[0m, \u001b[1;36m33\u001b[0m, \u001b[1;36m12\u001b[0m\u001b[33m...\u001b[0m           test        \u001b[1;36m2\u001b[0m  \n",
       "\u001b[1;36m3\u001b[0m  \u001b[1m{\u001b[0m\u001b[32m'counts'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m1155982\u001b[0m, \u001b[1;36m9\u001b[0m, \u001b[1;36m1113\u001b[0m, \u001b[1;36m14\u001b[0m, \u001b[1;36m1109\u001b[0m, \u001b[1;36m17\u001b[0m, \u001b[1;36m11\u001b[0m\u001b[33m...\u001b[0m          train        \u001b[1;36m3\u001b[0m  \n",
       "\u001b[1;36m4\u001b[0m  \u001b[1m{\u001b[0m\u001b[32m'counts'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m1504206\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m1325\u001b[0m, \u001b[1;36m20\u001b[0m, \u001b[1;36m1313\u001b[0m, \u001b[1;36m26\u001b[0m, \u001b[1;36m13\u001b[0m\u001b[33m...\u001b[0m           test        \u001b[1;36m4\u001b[0m  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from wildlife_datasets.datasets import SeaTurtleID2022\n",
    "from wildlife_tools.data import ImageDataset\n",
    "from wildlife_datasets.splits import ClosedSetSplit\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = \"nashadammuoz\"\n",
    "os.environ['KAGGLE_KEY'] = \"KGAT_ef90b0c2a32630082bb12f03344b4421\"\n",
    "\n",
    "root = Path(\"dataset\")\n",
    "\n",
    "SeaTurtleID2022.get_data(root=root)\n",
    "dataset_df = SeaTurtleID2022(root=root, category_name=\"head\", img_load=\"bbox\").df\n",
    "dataset_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc51f6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.0287\u001b[0m,  \u001b[1;36m0.0227\u001b[0m,  \u001b[1;36m0.0569\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.9192\u001b[0m, \u001b[1;36m-0.9192\u001b[0m, \u001b[1;36m-0.9192\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.0458\u001b[0m,  \u001b[1;36m0.0398\u001b[0m,  \u001b[1;36m0.0741\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.9192\u001b[0m, \u001b[1;36m-0.9192\u001b[0m, \u001b[1;36m-0.9192\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.0629\u001b[0m,  \u001b[1;36m0.0398\u001b[0m,  \u001b[1;36m0.0912\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.9020\u001b[0m, \u001b[1;36m-0.9192\u001b[0m, \u001b[1;36m-0.9192\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[33m...\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.9020\u001b[0m, \u001b[1;36m-0.8849\u001b[0m, \u001b[1;36m-0.8849\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.4226\u001b[0m, \u001b[1;36m-0.4054\u001b[0m, \u001b[1;36m-0.4054\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.8849\u001b[0m, \u001b[1;36m-0.8678\u001b[0m, \u001b[1;36m-0.8335\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.4568\u001b[0m, \u001b[1;36m-0.4226\u001b[0m, \u001b[1;36m-0.3883\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.9020\u001b[0m, \u001b[1;36m-0.8678\u001b[0m, \u001b[1;36m-0.8164\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.4739\u001b[0m, \u001b[1;36m-0.4226\u001b[0m, \u001b[1;36m-0.3712\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\n",
       "        \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m0.7829\u001b[0m,  \u001b[1;36m0.8004\u001b[0m,  \u001b[1;36m0.7829\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.3978\u001b[0m,  \u001b[1;36m0.3978\u001b[0m,  \u001b[1;36m0.3978\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0.7654\u001b[0m,  \u001b[1;36m0.8179\u001b[0m,  \u001b[1;36m0.8004\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.3978\u001b[0m,  \u001b[1;36m0.3978\u001b[0m,  \u001b[1;36m0.3978\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0.7654\u001b[0m,  \u001b[1;36m0.8179\u001b[0m,  \u001b[1;36m0.8004\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.4153\u001b[0m,  \u001b[1;36m0.3978\u001b[0m,  \u001b[1;36m0.3978\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[33m...\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0.2227\u001b[0m,  \u001b[1;36m0.2402\u001b[0m,  \u001b[1;36m0.2577\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.3978\u001b[0m,  \u001b[1;36m0.4153\u001b[0m,  \u001b[1;36m0.4153\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0.2402\u001b[0m,  \u001b[1;36m0.2577\u001b[0m,  \u001b[1;36m0.2927\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.3627\u001b[0m,  \u001b[1;36m0.3978\u001b[0m,  \u001b[1;36m0.4328\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0.2227\u001b[0m,  \u001b[1;36m0.2577\u001b[0m,  \u001b[1;36m0.3102\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.3452\u001b[0m,  \u001b[1;36m0.3978\u001b[0m,  \u001b[1;36m0.4503\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\n",
       "        \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m2.3786\u001b[0m,  \u001b[1;36m2.4134\u001b[0m,  \u001b[1;36m2.4308\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m1.3502\u001b[0m,  \u001b[1;36m1.3502\u001b[0m,  \u001b[1;36m1.3502\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m2.2914\u001b[0m,  \u001b[1;36m2.4308\u001b[0m,  \u001b[1;36m2.4483\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m1.3502\u001b[0m,  \u001b[1;36m1.3502\u001b[0m,  \u001b[1;36m1.3502\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m2.2217\u001b[0m,  \u001b[1;36m2.3786\u001b[0m,  \u001b[1;36m2.4831\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m1.3677\u001b[0m,  \u001b[1;36m1.3502\u001b[0m,  \u001b[1;36m1.3502\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[33m...\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0.6879\u001b[0m,  \u001b[1;36m0.7054\u001b[0m,  \u001b[1;36m0.7054\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.6182\u001b[0m,  \u001b[1;36m0.6356\u001b[0m,  \u001b[1;36m0.6356\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0.6879\u001b[0m,  \u001b[1;36m0.7054\u001b[0m,  \u001b[1;36m0.7402\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.5834\u001b[0m,  \u001b[1;36m0.6182\u001b[0m,  \u001b[1;36m0.6356\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0.6531\u001b[0m,  \u001b[1;36m0.6879\u001b[0m,  \u001b[1;36m0.7402\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.5485\u001b[0m,  \u001b[1;36m0.6008\u001b[0m,  \u001b[1;36m0.6531\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mnp.int64\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def safe_split(df, name, seed):\n",
    "    if len(df) == 0:\n",
    "        raise ValueError(f\"DataFrame for {name} is empty, cannot split.\")\n",
    "        \n",
    "    splitter = ClosedSetSplit(ratio_train=0.5, seed=seed)\n",
    "    splits = splitter.split(df)\n",
    "    \n",
    "    if len(splits) == 0:\n",
    "         print(f\"WARNING: Splitter returned no splits for {name}\")\n",
    "         return df, df\n",
    "\n",
    "    gallery_idx, query_idx = splits[0]\n",
    "    \n",
    "    # Verify indices are valid\n",
    "    if gallery_idx.max() >= len(df) or query_idx.max() >= len(df):\n",
    "         raise IndexError(f\"Splitter returned invalid indices for {name}. Max idx: {gallery_idx.max()}, DF len: {len(df)}\")\n",
    "\n",
    "    gal_df = df.iloc[gallery_idx].reset_index(drop=True)\n",
    "    qry_df = df.iloc[query_idx].reset_index(drop=True)\n",
    "    return gal_df, qry_df\n",
    "\n",
    "def generate_query_gallery_splits(df, seed, img_size, root):\n",
    "    gallery_df, query_df = safe_split(df, \"Dataset Split\", seed)\n",
    "    t_eval = T.Compose([\n",
    "        T.Resize((img_size, img_size)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    gallery_set = ImageDataset(\n",
    "        gallery_df,\n",
    "        root=root,\n",
    "        transform=t_eval,\n",
    "        col_path='path',\n",
    "        col_label='identity'\n",
    "    )\n",
    "    query_set = ImageDataset(\n",
    "        query_df,\n",
    "        root=root,\n",
    "        transform=t_eval,\n",
    "        col_path='path',\n",
    "        col_label='identity'\n",
    "    )\n",
    "    return gallery_set, query_set\n",
    "\n",
    "test_df = dataset_df[dataset_df['original_split'] == 'test'].reset_index(drop=True)\n",
    "test_gallery_set, test_query_set = generate_query_gallery_splits(test_df, seed=42, img_size=384, root=root)\n",
    "\n",
    "test_gallery_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dde18501",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ConvNeXtBackbone:\n\tMissing key(s) in state_dict: \"contrastive_head.0.weight\", \"contrastive_head.0.bias\", \"contrastive_head.2.weight\", \"contrastive_head.2.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 96\u001b[39m\n\u001b[32m     94\u001b[39m fl_method = \u001b[33m'\u001b[39m\u001b[33mfedprox\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     95\u001b[39m backbone_state = Path(\u001b[33m'\u001b[39m\u001b[33mpretrained_models\u001b[39m\u001b[33m'\u001b[39m) / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfl_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pth\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[43mbackbone\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackbone_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# NOTE GENERATE EMBEDDINGS FOR GALLERY IMAGES FIRST\u001b[39;00m\n\u001b[32m     99\u001b[39m sample_query_img, sample_query_label = test_query_set[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Federated_SeaTurtleReID/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:2635\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2627\u001b[39m         error_msgs.insert(\n\u001b[32m   2628\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2629\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2630\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2631\u001b[39m             ),\n\u001b[32m   2632\u001b[39m         )\n\u001b[32m   2634\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2635\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2636\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2637\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2638\u001b[39m         )\n\u001b[32m   2639\u001b[39m     )\n\u001b[32m   2640\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for ConvNeXtBackbone:\n\tMissing key(s) in state_dict: \"contrastive_head.0.weight\", \"contrastive_head.0.bias\", \"contrastive_head.2.weight\", \"contrastive_head.2.bias\". "
     ]
    }
   ],
   "source": [
    "from torchvision.models import convnext_base, ConvNeXt_Base_Weights\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Prediction\n",
    "class ConvNeXtBackbone(nn.Module):\n",
    "    \"\"\"\n",
    "    ConvNeXt Backbone for Feature Extraction.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim=512, dropout=0.2, pretrained=True):\n",
    "        super().__init__()\n",
    "        weights = ConvNeXt_Base_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        model = convnext_base(weights=weights)\n",
    "        \n",
    "        # Remove original classifier\n",
    "        in_features = model.classifier[2].in_features\n",
    "        model.classifier[2] = nn.Identity()\n",
    "        self.backbone = model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.proj = nn.Linear(in_features, embedding_dim)\n",
    "\n",
    "        self.contrastive_head = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_dim, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        feat = self.dropout(feat)\n",
    "        emb = self.proj(feat)\n",
    "        norms = torch.norm(emb, p=2, dim=1, keepdim=True)\n",
    "        emb = F.normalize(emb, dim=1)\n",
    "        projected_emb = self.contrastive_head(emb)\n",
    "        return emb, projected_emb, norms.flatten()\n",
    "\n",
    "# Wrapper Model\n",
    "class ReIDModel(nn.Module): \n",
    "    \"\"\"\n",
    "    ReID Model combining Backbone and Head.\n",
    "    \"\"\"\n",
    "    def __init__(self, backbone, head):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.head = head\n",
    "\n",
    "    def forward(self, x, labels=None, prediction=False):\n",
    "        emb, projected_emb, norms = self.backbone(x)\n",
    "        if labels is not None:\n",
    "            logits = self.head(emb, norms, labels)\n",
    "            return logits, projected_emb\n",
    "        if prediction:\n",
    "            return emb\n",
    "        return projected_emb\n",
    "\n",
    "def predict(model, query_img, gallery_set, device='cpu'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    print(\"Predicting query embedding...\")\n",
    "    with torch.no_grad():\n",
    "        query_img = query_img.to(device).unsqueeze(0)\n",
    "        query_emb = model(query_img, prediction=True).cpu()\n",
    "        print(\"Query embedding predicted.\")\n",
    "        \n",
    "\n",
    "    gallery_loader = torch.utils.data.DataLoader(gallery_set, batch_size=32, shuffle=False)\n",
    "    gallery_embeddings = []\n",
    "    gallery_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_imgs, batch_labels in tqdm(gallery_loader, desc=\"Processing gallery batches\"):\n",
    "            batch_imgs = batch_imgs.to(device)\n",
    "            batch_embs = model(batch_imgs, prediction=True).cpu()\n",
    "            gallery_embeddings.append(batch_embs.cpu())\n",
    "            gallery_labels.append(batch_labels)\n",
    "        \n",
    "    gallery_embeddings = torch.cat(gallery_embeddings, dim=0)\n",
    "        \n",
    "    # Compute distances\n",
    "    query_emb = query_emb.cpu()\n",
    "    similarities = torch.mm(query_emb, gallery_embeddings.t())\n",
    "    sorted_indices = torch.argsort(similarities, dim=1, descending=True)\n",
    "        \n",
    "    return sorted_indices.squeeze().tolist(), gallery_labels\n",
    "\n",
    "# Load pretrained model\n",
    "backbone = ConvNeXtBackbone(embedding_dim=512)\n",
    "eval_model = ReIDModel(backbone=backbone, head=nn.Identity()).to('cpu')\n",
    "\n",
    "fl_method = 'fedprox'\n",
    "backbone_state = Path('pretrained_models') / f\"{fl_method}.pth\"\n",
    "backbone.load_state_dict(torch.load(backbone_state, map_location='cpu'))\n",
    "\n",
    "# NOTE GENERATE EMBEDDINGS FOR GALLERY IMAGES FIRST\n",
    "sample_query_img, sample_query_label = test_query_set[0]\n",
    "sorted_gallery_indices, gallery_labels = predict(eval_model, sample_query_img, test_gallery_set, device='cpu')\n",
    "print(\"Sorted gallery indices (closest to farthest):\")\n",
    "print(sorted_gallery_indices[5])\n",
    "print(\"Corresponding gallery labels:\")\n",
    "print(gallery_labels[5])\n",
    "\n",
    "fig, ax = plt.subplots(1, 6, figsize=(15, 5))\n",
    "ax[0].imshow(sample_query_img.permute(1, 2, 0))\n",
    "ax[0].set_title(f\"Query ID: {sample_query_label}\")\n",
    "ax[0].axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
